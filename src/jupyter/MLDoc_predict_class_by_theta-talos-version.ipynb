{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD\n",
    "import numpy as np\n",
    "import talos as ta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Corpus = pd.read_pickle(\"../out/MLDoc/Shuffled_RS168_tagged_englishAndchinese_corpus_pd.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MCAT    1253\n",
       "ECAT    1215\n",
       "CCAT    1169\n",
       "GCAT     363\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Corpus[(Corpus[\"Data_type\"] == \"test\") & (Corpus[\"language\"] == \"Chinese\")][\"Class\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_theta(theta_file):\n",
    "    delimiter = \" \"\n",
    "    thetas = []\n",
    "    file = open(theta_file, \"r\")\n",
    "    for each_theta in file.readlines():\n",
    "        thetas.append(each_theta.strip(\"\\n\").split(delimiter)[:-1])\n",
    "    return thetas\n",
    "\n",
    "def transform_pd_to_numpy_data(pd_Corpus):\n",
    "    \n",
    "    '''\n",
    "    data_count = pd_Corpus.groupby('Data_type').size()\n",
    "    training_size = data_count[\"train\"]\n",
    "    testing_size = data_count[\"test\"]\n",
    "    dev_size = data_count[\"dev\"]\n",
    "    input_feature_size = len(pd_Corpus[\"theta\"][0])\n",
    "    '''\n",
    "    \n",
    "    class_dictionary = {}\n",
    "    class_count = pd_Corpus.groupby('Class').size()\n",
    "    for key, _ in class_count.iteritems():\n",
    "        class_dictionary[key] = len(class_dictionary)\n",
    "    \n",
    "    class_size = len(class_dictionary)\n",
    "    \n",
    "    Data_Object = {}\n",
    "    Data_Object[\"x_train\"] = np.array(Corpus[Corpus[\"Data_type\"] == \"train\"][\"theta\"].values.tolist())\n",
    "    Data_Object[\"y_train\"] = keras.utils.to_categorical(np.array(Corpus[Corpus[\"Data_type\"] == \"train\"][\"Class\"].apply(\n",
    "                                lambda x: class_dictionary[x]).tolist()), num_classes=class_size)\n",
    "    Data_Object[\"x_dev\"] = np.array(Corpus[Corpus[\"Data_type\"] == \"dev\"][\"theta\"].values.tolist())\n",
    "    Data_Object[\"y_dev\"] = keras.utils.to_categorical(np.array(Corpus[Corpus[\"Data_type\"] == \"dev\"][\"Class\"].apply(\n",
    "                                lambda x: class_dictionary[x]).tolist()), num_classes=class_size)\n",
    "    '''\n",
    "    Data_Object[\"x_test\"] = np.array(Corpus[Corpus[\"Data_type\"] == \"test\"][\"theta\"].values.tolist())\n",
    "    Data_Object[\"y_test\"] = keras.utils.to_categorical(np.array(Corpus[Corpus[\"Data_type\"] == \"test\"][\"Class\"].apply(\n",
    "                                lambda x: class_dictionary[x]).tolist()), num_classes=class_size)\n",
    "    '''\n",
    "    Data_Object[\"x_test\"] = np.array(Corpus[(Corpus[\"Data_type\"] == \"test\") &\n",
    "                                            (Corpus[\"language\"] == \"Chinese\")][\"theta\"].values.tolist())\n",
    "    Data_Object[\"y_test\"] = keras.utils.to_categorical(np.array(Corpus[(Corpus[\"Data_type\"] == \"test\") &\n",
    "                                                                       (Corpus[\"language\"] == \"Chinese\")][\"Class\"].apply(\n",
    "                                lambda x: class_dictionary[x]).tolist()), num_classes=class_size)\n",
    "    \n",
    "    return Data_Object, class_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLTM_theta = read_theta(\"../out/Experiment_results/CLTM/2018-11-27/10dim-MLDoc-engAndchi-LFLDA10T100I1e-1beta.theta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Corpus[\"theta\"] = CLTM_theta\n",
    "Data_Object, class_dictionary = transform_pd_to_numpy_data(Corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000, 10)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data_Object[\"x_test\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('MLDoc_90dim_10topics_data_object.pickle', 'wb') as handle:\n",
    "    pickle.dump(Data_Object, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "# Dense(64) is a fully-connected layer with 64 hidden units.\n",
    "# in the first layer, you must specify the expected input data shape:\n",
    "# here, 10-dimensional vectors.\n",
    "model.add(Dense(64, activation='relu', input_dim=10))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(4, activation='softmax'))\n",
    "\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(Data_Object[\"x_train\"], Data_Object[\"y_train\"],\n",
    "          epochs=500,\n",
    "          batch_size=256,\n",
    "          validation_data=[Data_Object[\"x_dev\"], Data_Object[\"y_dev\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 9us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6689969706535339, 0.747625]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = model.evaluate(Data_Object[\"x_test\"], Data_Object[\"y_test\"], batch_size=256)\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Talos tuning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MLDoc_Predictive_Model(x_train, y_train, x_val, y_val, params):\n",
    "    \n",
    "    first_neuron = int(params['first_neuron'])\n",
    "    dropout = float(params['dropout'])\n",
    "    learning_rate = float(params['learning_rate'])\n",
    "    decay_rate = float(params['decay_rate'])\n",
    "    epochs_num = int(params['epochs_num'])\n",
    "    batch_size_num = int(params['batch_size_num'])\n",
    "    \n",
    "    model = Sequential()\n",
    "    # Dense(64) is a fully-connected layer with 64 hidden units.\n",
    "    # in the first layer, you must specify the expected input data shape:\n",
    "    # here, 10-dimensional vectors.\n",
    "    model.add(Dense(first_neuron, activation='relu', input_dim=x_train.shape[1]))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Dense(4, activation='softmax'))\n",
    "\n",
    "    sgd = SGD(lr=learning_rate, decay=decay_rate, momentum=0.9, nesterov=True)\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=sgd,\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    out = model.fit(x_train, y_train,\n",
    "          epochs=epochs_num,\n",
    "          batch_size=batch_size_num,\n",
    "          verbose=0,\n",
    "          validation_data=[x_val, y_val])\n",
    "    \n",
    "    return out, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = {'learning_rate': (0.01, 0.1, 5),\n",
    "     'decay_rate': [1e-6, 1e-5, 1e-4],\n",
    "     'first_neuron': [8, 16, 32, 64, 128],\n",
    "     'batch_size_num': [32, 64, 128, 256, 512],\n",
    "     'epochs_num': [500],\n",
    "     'dropout': (0, 0.50, 5)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [38:47<00:00, 20.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scan Finished!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "h = ta.Scan(x=Data_Object[\"x_train\"], y=Data_Object[\"y_train\"],\n",
    "          x_val=Data_Object[\"x_dev\"],y_val=Data_Object[\"y_dev\"],\n",
    "          params=p,\n",
    "          dataset_name='MLDoc_90dim_10topics',\n",
    "          experiment_no='1',\n",
    "          model=MLDoc_Predictive_Model,\n",
    "          grid_downsample=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"class_name\": \"Sequential\", \"config\": {\"name\": \"sequential_1\", \"layers\": [{\"class_name\": \"Dense\", \"config\": {\"name\": \"dense_1\", \"trainable\": true, \"batch_input_shape\": [null, 10], \"dtype\": \"float32\", \"units\": 128, \"activation\": \"relu\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"VarianceScaling\", \"config\": {\"scale\": 1.0, \"mode\": \"fan_avg\", \"distribution\": \"uniform\", \"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}, {\"class_name\": \"Dropout\", \"config\": {\"name\": \"dropout_1\", \"trainable\": true, \"rate\": 0.4, \"noise_shape\": null, \"seed\": null}}, {\"class_name\": \"Dense\", \"config\": {\"name\": \"dense_2\", \"trainable\": true, \"units\": 4, \"activation\": \"softmax\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"VarianceScaling\", \"config\": {\"scale\": 1.0, \"mode\": \"fan_avg\", \"distribution\": \"uniform\", \"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}]}, \"keras_version\": \"2.2.4\", \"backend\": \"tensorflow\"}\n"
     ]
    }
   ],
   "source": [
    "best_model_id = h.data['val_acc'].astype('float').argmax() - 1\n",
    "print(h.saved_models[best_model_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = h.saved_models[best_model_id]\n",
    "best_model = keras.models.model_from_json(best_model)\n",
    "best_model.set_weights(h.saved_weights[best_model_id])\n",
    "best_model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=\"sgd\",\n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000/4000 [==============================] - 0s 20us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6402635846138001, 0.7855000009536743]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.evaluate(Data_Object[\"x_test\"], Data_Object[\"y_test\"], batch_size=256)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cross-lingual]",
   "language": "python",
   "name": "conda-env-cross-lingual-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

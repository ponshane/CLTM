{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "from gensim.models import TranslationMatrix, translation_matrix\n",
    "\n",
    "def normalised(mat, axis=-1, order=2):\n",
    "        \"\"\"Utility function to normalise the rows of a numpy array.\"\"\"\n",
    "        norm = np.linalg.norm(\n",
    "            mat, axis=axis, ord=order, keepdims=True)\n",
    "        norm[norm == 0] = 1\n",
    "        return mat / norm\n",
    "    \n",
    "def export_to_KeyedVectors(transformed_source_model, target_model, file_path):\n",
    "        \n",
    "        target_model.init_sims()\n",
    "        \n",
    "        print(\"transform_source_model.shape = \", transformed_source_model.mat.shape)\n",
    "        print(\"target_model.shape = \", target_model.wv.vectors_norm.shape)\n",
    "\n",
    "        two_languages_index2word = transformed_source_model.index2word + target_model.wv.index2word\n",
    "        normalised_transform_embedding = normalised(transformed_source_model.mat)\n",
    "        print(\"Normalization is finished!\")\n",
    "        \n",
    "        two_languages_word_vector = np.concatenate((normalised_transform_embedding,\\\n",
    "                                              target_model.wv.vectors_norm), axis=0)\n",
    "        print(\"concatenate_model.shape = \", two_languages_word_vector.shape)\n",
    "\n",
    "        out = open(file_path,'w')\n",
    "        out.write(str(two_languages_word_vector.shape[0]) + \" \" + str(two_languages_word_vector.shape[1]))\n",
    "        out.write(\"\\n\")\n",
    "        for each_word in two_languages_index2word:\n",
    "            out.write(each_word + \" \")\n",
    "            out.write(' '.join(map(str, two_languages_word_vector[two_languages_index2word.index(each_word)])) + \"\\n\")\n",
    "        out.close()\n",
    "\n",
    "        print(\"KeyedVectors have exported to\", file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "chinese_vec_file = \"/home/ponshane/jupyter_working_dir/cross-lingual-topic-analysis/UM_Corpus_vectors/2018-02-19-ponshane-um-corpus-chinese-NEWS-word2vec_NV_s100w5m15n10s1e-04.vec\"\n",
    "english_vec_file = \"/home/ponshane/jupyter_working_dir/cross-lingual-topic-analysis/UM_Corpus_vectors/2018-02-19-ponshane-um-corpus-english-NEWS-word2vec_NV_s100w5m15n10s8e-05.vec\"\n",
    "\n",
    "chinese_model = Word2Vec.load(chinese_vec_file)\n",
    "english_model = Word2Vec.load(english_vec_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21571, 100)\n",
      "(29818, 100)\n"
     ]
    }
   ],
   "source": [
    "print(english_model.wv.vectors.shape)\n",
    "print(chinese_model.wv.vectors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"./UM-Corpus-hand-craft-zh-en-3000.txt\", \"r\")\n",
    "\n",
    "word_pairs = []\n",
    "\n",
    "for line in f.readlines():\n",
    "    line = line.rstrip(\"\\n\").split(\" \")\n",
    "    #print(line[0], line[1].lower())\n",
    "    chinese_word = line[0]\n",
    "    english_word = line[1].lower()\n",
    "    if chinese_word in chinese_model.wv.index2word and english_word in english_model.wv.index2word:\n",
    "        word_pairs.append((chinese_word, english_word))\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2746"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_model = TranslationMatrix(chinese_model.wv, english_model.wv)\n",
    "trans_model.train(word_pairs)\n",
    "trans_model.translate([\"增加\", \"政府\"], topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform datatype\n",
    "chinese_model_space = translation_matrix.Space(chinese_model.wv.vectors, index2word=chinese_model.wv.index2word)\n",
    "# transform space\n",
    "transformed_Chinese_model = trans_model.apply_transmat(chinese_model_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transform_source_model.shape =  (6733, 100)\n",
      "target_model.shape =  (19982, 100)\n",
      "Normalization is finished!\n",
      "concatenate_model.shape =  (26715, 100)\n",
      "KeyedVectors have exported to ../out/MLDoc/Chinese_English_wordvectors.vec\n"
     ]
    }
   ],
   "source": [
    "export_to_KeyedVectors(transformed_Chinese_model, english_model, \"/home/ponshane/work_dir/CLTM-Experiments/Data/UM-Corpus/word-vectors/Hand_Craft_Chinese_English_WordVectors.vec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test phase\n",
    "Concatenated_model = KeyedVectors.load_word2vec_format(\"/home/ponshane/work_dir/CLTM-Experiments/Data/UM-Corpus/word-vectors/Hand_Craft_Chinese_English_WordVectors.vec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('政府', 0.9339044094085693),\n",
       " ('pledged', 0.894436240196228),\n",
       " ('granting', 0.8840190172195435),\n",
       " ('美国政府', 0.8780467510223389),\n",
       " ('mandate', 0.8754358887672424),\n",
       " ('联邦政府', 0.8733851909637451),\n",
       " ('governments', 0.8718053102493286),\n",
       " ('proposals', 0.8657378554344177),\n",
       " ('immigration', 0.8610117435455322),\n",
       " ('几比', 0.860572099685669),\n",
       " ('authorities', 0.8599981069564819),\n",
       " ('authority', 0.8594396114349365),\n",
       " ('捐助国', 0.8571164608001709),\n",
       " ('donors', 0.853731632232666),\n",
       " ('达成协议', 0.8526170253753662),\n",
       " ('控制权', 0.8514776229858398),\n",
       " ('reforms', 0.8506940603256226),\n",
       " ('demanding', 0.8499373197555542),\n",
       " ('legislation', 0.846879243850708),\n",
       " ('bailout', 0.8448300361633301)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Concatenated_model.most_similar(\"government\", topn=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ponshane/anaconda3/envs/cross-lingual/lib/python3.6/site-packages/ipykernel/__main__.py:4: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "/home/ponshane/anaconda3/envs/cross-lingual/lib/python3.6/site-packages/ipykernel/__main__.py:13: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n"
     ]
    }
   ],
   "source": [
    "# export to embedding projector\n",
    "file_path = \"./UM-Corpus_handcraft_Concatenated_embeddings.tsv\"\n",
    "out = open(file_path,'w')\n",
    "\n",
    "for each_word in Concatenated_model.wv.index2word:\n",
    "    out.write('\\t'.join(map(str, Concatenated_model[each_word])) + \"\\n\")\n",
    "\n",
    "out.close()\n",
    "\n",
    "# expoert to metadata file\n",
    "file_path = \"./UM-Corpus_handcraft_Concatenated_metadata.tsv\"\n",
    "out = open(file_path,'w')\n",
    "out.write(\"word\\tlanguage\\n\")\n",
    "for each_word in Concatenated_model.wv.index2word:\n",
    "    if each_word in chinese_model.wv.index2word:\n",
    "        out.write(each_word+\"\\tchinese\\n\")\n",
    "    else:\n",
    "        out.write(each_word+\"\\tenglish\\n\")\n",
    "\n",
    "out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# set python syspath to point out location of our self-writing module\n",
    "sys.path.append(\"/home/ponshane/work_dir/CLTM/src/codebase/\")\n",
    "\n",
    "from Docs_Input_Generator import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already process 2500 documents\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:04.221036\n",
      "Already process 5000 documents\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:04.243962\n",
      "Already process 7500 documents\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:04.266402\n",
      "Already process 10000 documents\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:06.057480\n",
      "Already process 12500 documents\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:06.082258\n",
      "Already process 15000 documents\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:06.106703\n",
      "Already process 17500 documents\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:06.130905\n",
      "Already process 20000 documents\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:07.872977\n",
      "Already process 22500 documents\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:07.898923\n",
      "Already process 25000 documents\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:07.924207\n",
      "Already process 25000 documents\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:07.924236\n"
     ]
    }
   ],
   "source": [
    "root_path = \"/home/ponshane/work_dir/temp/\"\n",
    "vector_path = \"/home/ponshane/work_dir/CLTM-Experiments/Data/UM-Corpus/word-vectors/80dim-vec-hand-craft.txt\"\n",
    "show_up_dict = export_selected_documents(word_vector_path=vector_path, output_path=root_path,\n",
    "                                             doc_num=25000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cross-lingual]",
   "language": "python",
   "name": "conda-env-cross-lingual-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

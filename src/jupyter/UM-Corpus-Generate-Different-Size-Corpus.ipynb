{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Experiment on different size of UM-Corpus\n",
    "pairs: [25k, 50k, 100K, 200K]\n",
    "total_n: [50k, 100k, 200K, 400K] <- as folder name\n",
    "\n",
    "prerequiste: 80dim-original-vectors.txt\n",
    "\n",
    "Step1: generate documents for four methods\n",
    "    - PLTM specific doc type\n",
    "    - CTLM one line for source anther for target\n",
    "    - JointLDA and PMLDA use the same doc type\n",
    "Step2: generate correspind *K-selected-80dim-word-vector.txt\n",
    "\n",
    "history:\n",
    "\n",
    "python ./src/run_dim_selector.py --embedding_file /home/ponshane/jupyter_working_dir/cross-lingual-topic-analysis/UM_Corpus_vectors/2018-09-27-ponshane-um-concatenate-wordvec-mikolov-100d.vec --file_path /home/ponshane/work_dir/CLTM-Experiments/Data/UM-Corpus/word-vectors/ --postfix dim-original-vectors.txt --start_dim 10 --end_dim 11 --step_size 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# set python syspath to point out location of our self-writing module\n",
    "sys.path.append(\"/home/ponshane/work_dir/CLTM/src/codebase/\")\n",
    "\n",
    "from Docs_Input_Generator import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc_size, folder_name in zip([50000, 100000, 200000, 400000],\n",
    "                                 [\"100K-sampled-docs/\", \"200K-sampled-docs/\", \"400K-sampled-docs/\", \"800K-sampled-docs/\"]):\n",
    "    root_path = \"/home/ponshane/work_dir/CLTM-Experiments/Data/UM-Corpus/\"\n",
    "    vector_path = \"/home/ponshane/work_dir/CLTM-Experiments/Data/UM-Corpus/word-vectors/80dim-original-vectors.txt\"\n",
    "    show_up_dict = export_selected_documents(word_vector_path=vector_path, output_path=root_path+folder_name,\n",
    "                                             doc_num=doc_size)\n",
    "    export_selected_word_space(vector_path=vector_path,\n",
    "                               word_dictionary=show_up_dict,\n",
    "                               outfilename=\"/home/ponshane/work_dir/CLTM-Experiments/Data/UM-Corpus/word-vectors/80dim_\" + str(int((doc_size*2)/1000)) + \"K_selected_vectors.txt\")\n",
    "# Already process 400000 documents\n",
    "# Time elapsed (hh:mm:ss.ms) 0:01:47.196353"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UM-Corpus 400K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = \"/home/ponshane/work_dir/CLTM-Experiments/Data/UM-Corpus/\"\n",
    "show_up_dict = dict()\n",
    "with open(\"/home/ponshane/work_dir/CLTM-Experiments/Data/UM-Corpus/800K-sampled-docs/selected800KDos.txt\", \"r\") as rf:\n",
    "    for doc in rf:\n",
    "        words = doc.rstrip().split(\" \")\n",
    "        for word in words:\n",
    "            show_up_dict[word] = True\n",
    "\n",
    "for i in [10,20,40,60,90,100]:\n",
    "    vector_path = f\"/home/ponshane/work_dir/CLTM-Experiments/Data/UM-Corpus/original-word-vectors/{i}dim-original-vectors.txt\"\n",
    "    export_selected_word_space(vector_path=vector_path,\n",
    "                               word_dictionary=show_up_dict,\n",
    "                               outfilename=f\"/home/ponshane/work_dir/CLTM-Experiments/Data/UM-Corpus/word-vectors/{i}dim_800K_selected_vectors.txt\")\n",
    "# Already process 400000 documents\n",
    "# Time elapsed (hh:mm:ss.ms) 0:01:47.196353"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_up_dict"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cross-lingual",
   "language": "python",
   "name": "cross-lingual"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

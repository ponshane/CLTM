{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "import ast\n",
    "import logging\n",
    "import os\n",
    "import re\n",
    "import xml.etree.ElementTree as ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "### init and read config\n",
    "config = configparser.ConfigParser()\n",
    "config.read('../config.ini')\n",
    "\n",
    "MongoDB = config[\"MLDoc\"][\"Database\"]\n",
    "MongoUser = config[\"MLDoc\"][\"User\"]\n",
    "MongoPW = config[\"MLDoc\"][\"PW\"]\n",
    "\n",
    "###連接MONGO\n",
    "uri = \"mongodb://\" + MongoUser + \":\" + MongoPW + \"@140.117.69.70:30241/\" +\\\n",
    "MongoDB + \"?authMechanism=SCRAM-SHA-1\"\n",
    "\n",
    "client = MongoClient(uri)\n",
    "db = client.MLDoc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load back MLDoc Pre-define indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "fo = open(\"/home/ponshane/work_dir/MLDoc/chinese.trian.10000.txt\", \"r\")\n",
    " \n",
    "for line in fo.readlines():\n",
    "    \n",
    "    line = line.split(\"\\t\")\n",
    "    # 確認只有 class, content of document\n",
    "    assert len(line) == 2\n",
    "    # ast help to read in bytes string\n",
    "    doc = ast.literal_eval(line[1]).decode('utf-8')\n",
    "    db.Chinese.insert_one({\"Class\":line[0], \"Content\":doc})\n",
    "\n",
    "fo.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# loop rcv2 specific language and store into Mongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_xml(rcv_dir, line):\n",
    "    delim_str = '\\t'\n",
    "    sentence_delim = ' '\n",
    "    code_class = 'bip:topics:1.0'\n",
    "    labels = ['C', 'E', 'G', 'M']\n",
    "    target_topics = ['{}CAT'.format(label) for label in labels]\n",
    "    \n",
    "    sub_corpus, file_name = line.strip().split('-')\n",
    "    sub_corpus_path = os.sep.join([rcv_dir, sub_corpus])\n",
    "    doc_path = os.sep.join(\n",
    "        [sub_corpus_path, '{}.xml'.format(file_name)]\n",
    "    )\n",
    "    data_str = open(doc_path).read()\n",
    "    try:\n",
    "        xml_parsed = ET.fromstring(data_str)\n",
    "        topics = [\n",
    "            topic.attrib['code'] for topic in xml_parsed.findall(\n",
    "                \".//codes[@class='{}']/code\".format(code_class)\n",
    "            ) if topic.attrib['code'] in target_topics\n",
    "        ]\n",
    "        assert len(topics) == 1, 'More than one class label found.'\n",
    "        doc = sentence_delim.join(\n",
    "            [p.text for p in xml_parsed.findall(\".//p\")]\n",
    "        )\n",
    "        \n",
    "        return sub_corpus, file_name, topics[0], doc\n",
    "    \n",
    "    except Exception as e:\n",
    "        logging.error('Failed to parse xml file: {}.'.format(doc_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to adjust following two inputs\n",
    "regex = r\"rcv1\\/(.+).xml\"\n",
    "rcv2_path = \"/home/ponshane/Desktop/rcv1\"\n",
    "\n",
    "for current_path, folder, files in os.walk(rcv2_path):\n",
    "    for file in files:\n",
    "        file_str = os.sep.join([current_path, file])\n",
    "        matches = re.search(regex, file_str, re.DOTALL)\n",
    "        if matches:    \n",
    "            index = matches.group(1).replace(\"/\",\"-\")+\"\\n\"\n",
    "            \n",
    "            try:\n",
    "                sub_corpus, file_name, topic_code, doc = parse_xml(rcv2_path, index)\n",
    "            except:\n",
    "                continue\n",
    "            \n",
    "            db.English.insert_one({\"Class\":topic_code, \"Content\":doc,\n",
    "                                  \"Sub_corpus\":sub_corpus, \"File_name\":file_name})\n",
    "f.close()\n",
    "\n",
    "# step1, generate_documents.py \n",
    "# step2, sampling_rcv2.py (可能要想想怎麼做，與後續實驗有關)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testcase\n",
    "sub_corpus, file_name, topic_code, doc = parse_xml(\"/home/ponshane/Desktop/RCV2_Multilingual_Corpus/chinese/\", \"FDCH14-29640\")\n",
    "print(sub_corpus, file_name, topic_code, doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update function is designed to help pymongo update nlp results into Database\n",
    "\n",
    "def update(target_collection, doc_id, sentences, nested_token_list, if_abstract=True):\n",
    "    #Result = {\"entity_list\":entity_list, \"chunk_list\": chunk_list, \"entity_controlled_list\": entity_controlled_list, \"token_list\": token_list}\n",
    "    #print(Result)\n",
    "    if if_abstract:\n",
    "        target_collection.update_one({\"_id\": doc_id},\n",
    "                          {\n",
    "                              \"$set\":{\n",
    "                              \"body_sentences\": sentences,\n",
    "                              \"body_nested_token_list\": nested_token_list,\n",
    "                              \"body_nlp_process\": True\n",
    "                              }\n",
    "                          })\n",
    "    else:\n",
    "        target_collection.update_one({\"_id\": doc_id},\n",
    "                          {\n",
    "                              \"$set\":{\n",
    "                              \"sentences\": sentences,\n",
    "                              \"nested_token_list\": nested_token_list,\n",
    "                              \"nlp_process\": True\n",
    "                              }\n",
    "                          })\n",
    "\n",
    "def error_update(target_collection, doc_id, if_abstract=True):\n",
    "    if if_abstract:\n",
    "        target_collection.update_one({\"_id\": doc_id},\n",
    "                          {\n",
    "                              \"$set\":{\n",
    "                              \"abstract_nlp_error\": True\n",
    "                          }\n",
    "                        })\n",
    "    else:\n",
    "        target_collection.update_one({\"_id\": doc_id},\n",
    "                          {\n",
    "                              \"$set\":{\n",
    "                              \"nlp_error\": True\n",
    "                          }\n",
    "                        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cross-lingual",
   "language": "python",
   "name": "cross-lingual"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

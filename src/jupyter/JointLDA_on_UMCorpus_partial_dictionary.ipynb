{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from ptm import JointGibbsLDA, JointCorpus\n",
    "from ptm.utils import get_top_words\n",
    "from codebase.topic_evaluator import *\n",
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare corpus\n",
    "corpus = JointCorpus(source_corpus_file=\"../out/JointLDA_Inputs/50K_English_UM_Corpus.txt\",\n",
    "                     target_corpus_file=\"../out/JointLDA_Inputs/50K_Chinese_UM_Corpus.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"../out/JointLDA_Inputs/um-corpus-news-top-translation.csv\")\n",
    "\n",
    "updated_source_dict = {}\n",
    "updated_target_dict = {}\n",
    "\n",
    "# rebuild vocab dict for query JointLDA's topic word distribution\n",
    "reconcatenate_dict = []\n",
    "\n",
    "for line in f.readlines():\n",
    "    line = line.rstrip(\"\\n\").split(\",\")\n",
    "    #######\n",
    "    # Notice the order here!\n",
    "    #######\n",
    "    source_word = line[0].lower()\n",
    "    target_word = line[1]\n",
    "    if target_word in corpus.target_dict.token2id.keys() and source_word in corpus.source_dict.token2id.keys():\n",
    "        if target_word not in updated_target_dict.keys() and source_word not in updated_source_dict.keys():\n",
    "            updated_target_dict[target_word] = len(updated_target_dict)\n",
    "            updated_source_dict[source_word] = len(updated_source_dict)\n",
    "            reconcatenate_dict.append((source_word, target_word))\n",
    "f.close()\n",
    "\n",
    "assert len(updated_target_dict) == len(updated_source_dict) == len(reconcatenate_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_pair_file = open(\"../out/JointLDA_Inputs/10perc-um-corpus-news-top-translation.csv\", \"w\")\n",
    "for each_pair in reconcatenate_dict:\n",
    "    if random.random() > 0.9:\n",
    "        random_pair_file.write(each_pair[0] + \",\" + each_pair[1] + \"\\n\")\n",
    "random_pair_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus.update_doctionary(\"../out/JointLDA_Inputs/10perc-um-corpus-news-top-translation.csv\")\n",
    "corpus.convert_raw_corpus_to_trainable_corpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model\n",
    "n_topic=20\n",
    "model = JointGibbsLDA(n_doc=len(corpus.docs), n_concept=corpus.n_concept, n_s_vocab=corpus.n_s_vocab,\n",
    "                      n_t_vocab=corpus.n_t_vocab, n_topic=n_topic)\n",
    "model.fit(corpus.docs, corpus.language_flags, max_iter=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show top words\n",
    "for ti in range(n_topic):\n",
    "    top_words = get_top_words(model.TW, corpus.reconcatenate_dict, ti, n_words=30)\n",
    "    print('Topic', ti ,': ', top_words)\n",
    "    #print('Topic', ti ,': ', ','.join(top_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_topics_by_languages(n_topic, n_words, model, corpus):\n",
    "    source_topic_list = []\n",
    "    target_topic_list = []\n",
    "    for ti in range(n_topic):\n",
    "        top_words = get_top_words(model.TW, corpus.reconcatenate_dict, ti, n_words=n_words)\n",
    "        source_temp = []\n",
    "        target_temp = []\n",
    "        for word in top_words:\n",
    "            if isinstance(word, tuple):\n",
    "                source_temp.append(word[0])\n",
    "                target_temp.append(word[1])\n",
    "            elif isinstance(word, str):\n",
    "                try:\n",
    "                    word.encode(\"ascii\")\n",
    "                    source_temp.append(word)\n",
    "                except UnicodeEncodeError:\n",
    "                    target_temp.append(word)\n",
    "        source_topic_list.append(source_temp)\n",
    "        target_topic_list.append(target_temp)\n",
    "    return source_topic_list, target_topic_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_topic_list, target_topic_list = split_topics_by_languages(n_topic=20, n_words=100,\n",
    "                                                                 model=model, corpus=corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_file = \"/home/ponshane/work_dir/CLTM/src/out/CLTM_Inputs/2018-12-19/selected50KDos.txt\"\n",
    "cooccurence_matrix, _, compound_dictionary, num_of_documents = documents_to_cooccurence_matrix(corpus_file,\n",
    "                                                                                               is_pickle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for each_top in range(5, 55, 5):\n",
    "    c_s = coherence_score(cn_topic=target_topic_list, en_topic=source_topic_list,\n",
    "                topk=each_top, cooccurence_matrix=cooccurence_matrix,\n",
    "                compound_dictionary=compound_dictionary, num_of_documents=num_of_documents,\n",
    "                coherence_method=\"npmi\")\n",
    "    j_s = avg_jaccard_similarity_between_topics(target_topic_list, source_topic_list, each_top)\n",
    "    print(each_top, c_s, j_s)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cross-lingual]",
   "language": "python",
   "name": "conda-env-cross-lingual-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

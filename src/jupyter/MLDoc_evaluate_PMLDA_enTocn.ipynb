{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# set python syspath to point out location of our self-writing module\n",
    "sys.path.append(\"/home/ponshane/work_dir/CLTM/src\")\n",
    "\n",
    "from codebase.PMLDA import *\n",
    "from gensim.models.wrappers import LdaMallet\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "import parfit.parfit as pf\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_pd_to_numpy_data(Corpus, language):\n",
    "\n",
    "    '''\n",
    "    data_count = pd_Corpus.groupby('Data_type').size()\n",
    "    training_size = data_count[\"train\"]\n",
    "    testing_size = data_count[\"test\"]\n",
    "    dev_size = data_count[\"dev\"]\n",
    "    input_feature_size = len(pd_Corpus[\"theta\"][0])\n",
    "    '''\n",
    "\n",
    "    class_dictionary = {}\n",
    "    class_count = Corpus.groupby('Class').size()\n",
    "    for key, _ in class_count.iteritems():\n",
    "        class_dictionary[key] = len(class_dictionary)\n",
    "\n",
    "    class_size = len(class_dictionary)\n",
    "\n",
    "    Data_Object = {}\n",
    "    Data_Object[\"x_train\"] = np.array(Corpus[(Corpus[\"Data_type\"] == \"train\") &\n",
    "                                            (Corpus[\"language\"] == \"English\")][\"theta\"].values.tolist(), dtype=\"float\")\n",
    "    Data_Object[\"y_train\"] = np.array(Corpus[(Corpus[\"Data_type\"] == \"train\") &\n",
    "                                            (Corpus[\"language\"] == \"English\")][\"Class\"])\n",
    "    Data_Object[\"x_dev\"] = np.array(Corpus[(Corpus[\"Data_type\"] == \"dev\") &\n",
    "                                            (Corpus[\"language\"] == \"English\")][\"theta\"].values.tolist(), dtype=\"float\")\n",
    "    Data_Object[\"y_dev\"] = np.array(Corpus[(Corpus[\"Data_type\"] == \"dev\") &\n",
    "                                            (Corpus[\"language\"] == \"English\")][\"Class\"])\n",
    "    '''\n",
    "    Data_Object[\"x_test\"] = np.array(Corpus[Corpus[\"Data_type\"] == \"test\"][\"theta\"].values.tolist())\n",
    "    Data_Object[\"y_test\"] = keras.utils.to_categorical(np.array(Corpus[Corpus[\"Data_type\"] == \"test\"][\"Class\"].apply(\n",
    "                                lambda x: class_dictionary[x]).tolist()), num_classes=class_size)\n",
    "    '''\n",
    "    Data_Object[\"x_test\"] = np.array(Corpus[(Corpus[\"Data_type\"] == \"test\") &\n",
    "                                            (Corpus[\"language\"] == language)][\"theta\"].values.tolist(), dtype=\"float\")\n",
    "    Data_Object[\"y_test\"] = np.array(Corpus[(Corpus[\"Data_type\"] == \"test\") &\n",
    "                                                                       (Corpus[\"language\"] == language)][\"Class\"])\n",
    "\n",
    "    return Data_Object, class_dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLDoc English to Chinese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Start to initialize PMLDA\n",
      "INFO:gensim.utils:loading LdaMallet object from ../out/Mallet_Mono_LDA/MLDoc-Chinese-vs-English-iter500-alpha01-cn.model\n",
      "INFO:gensim.utils:loading id2word recursively from ../out/Mallet_Mono_LDA/MLDoc-Chinese-vs-English-iter500-alpha01-cn.model.id2word.* with mmap=None\n",
      "INFO:gensim.utils:loaded ../out/Mallet_Mono_LDA/MLDoc-Chinese-vs-English-iter500-alpha01-cn.model\n",
      "INFO:gensim.utils:loading LdaMallet object from ../out/Mallet_Mono_LDA/MLDoc-English-vs-Chinese-iter500-alpha01-en.model\n",
      "INFO:gensim.utils:loading id2word recursively from ../out/Mallet_Mono_LDA/MLDoc-English-vs-Chinese-iter500-alpha01-en.model.id2word.* with mmap=None\n",
      "INFO:gensim.utils:loaded ../out/Mallet_Mono_LDA/MLDoc-English-vs-Chinese-iter500-alpha01-en.model\n",
      "INFO:gensim.models.utils_any2vec:loading projection weights from ../out/CLTM_Inputs/90dim-MLDoc-engAndchi.txt\n",
      "INFO:gensim.models.utils_any2vec:loaded (26715, 90) matrix from ../out/CLTM_Inputs/90dim-MLDoc-engAndchi.txt\n",
      "INFO:root:Start to train model\n",
      "INFO:root:1) Select representative words\n",
      "INFO:root:2) Calculate centroid of topics\n",
      "INFO:root:3) Start to do hierarchical clustering\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 2, 4, 2, 3, 2]\n"
     ]
    }
   ],
   "source": [
    "pm = PMLDA(source_model_path=\"../out/Mallet_Mono_LDA/MLDoc-Chinese-vs-English-iter500-alpha01-cn.model\",\n",
    "    target_model_path=\"../out/Mallet_Mono_LDA/MLDoc-English-vs-Chinese-iter500-alpha01-en.model\",\n",
    "    vector_path=\"../out/CLTM_Inputs/90dim-MLDoc-engAndchi.txt\")\n",
    "\n",
    "pm.train(top_n_representative_words=50, num_of_topic=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: ['C2', 'C8', 'E4'],\n",
       " 1: ['C6', 'E1'],\n",
       " 2: ['C1', 'C7', 'E3', 'E9'],\n",
       " 3: ['C3', 'C4'],\n",
       " 4: ['C0', 'C5', 'C9'],\n",
       " 5: ['E2', 'E6'],\n",
       " 6: ['E7'],\n",
       " 7: ['E8'],\n",
       " 8: ['E5'],\n",
       " 9: ['E0']}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pm.member_of_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recalculating theta\n",
    "# 讓原始 topic index 為 key，對應到的 cross-lignual topic index 為 value\n",
    "chinese_topic_dictionary = {}\n",
    "english_topic_dictionary = {}\n",
    "for cross_index, original_indexes in pm.member_of_clusters.items():\n",
    "    for each_member in original_indexes:\n",
    "        if \"C\" in each_member:\n",
    "            chinese_topic_dictionary[int(each_member.strip(\"C\"))] = cross_index\n",
    "        elif \"E\" in each_member:\n",
    "            english_topic_dictionary[int(each_member.strip(\"E\"))] = cross_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.utils:loading LdaMallet object from ../out/Mallet_Mono_LDA/MLDoc-Chinese-vs-English-iter500-alpha01-cn.model\n",
      "INFO:gensim.utils:loading id2word recursively from ../out/Mallet_Mono_LDA/MLDoc-Chinese-vs-English-iter500-alpha01-cn.model.id2word.* with mmap=None\n",
      "INFO:gensim.utils:loaded ../out/Mallet_Mono_LDA/MLDoc-Chinese-vs-English-iter500-alpha01-cn.model\n"
     ]
    }
   ],
   "source": [
    "chinese_doc_topics = \"../out/Mallet_Mono_LDA/MLDoc-Chinese-vs-English-topic10-doctopics.txt\"\n",
    "english_doc_topics = \"../out/Mallet_Mono_LDA/MLDoc-English-vs-Chinese-topic10-doctopics.txt\"\n",
    "\n",
    "chinese_model = LdaMallet.load(\"../out/Mallet_Mono_LDA/MLDoc-Chinese-vs-English-iter500-alpha01-cn.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recalculate_theta(mapping_dictionary, original_theta_file):\n",
    "    \n",
    "    all_transformed_theta = []\n",
    "    \n",
    "    orginal_theta = chinese_model.read_doctopics(fname=original_theta_file)\n",
    "    for each_theta in orginal_theta:\n",
    "        \n",
    "        transformed_theta = [0]*len(mapping_dictionary)\n",
    "        assert len(each_theta) == len(mapping_dictionary)\n",
    "        \n",
    "        for idx, topic_tuple in enumerate(each_theta):\n",
    "            transformed_theta[mapping_dictionary[idx]] += topic_tuple[1]\n",
    "        \n",
    "        all_transformed_theta.append(transformed_theta)\n",
    "        \n",
    "    return all_transformed_theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "chinese_transformed_theta = recalculate_theta(chinese_topic_dictionary, chinese_doc_topics)\n",
    "english_transformed_theta = recalculate_theta(english_topic_dictionary, english_doc_topics)\n",
    "PMLDA_theta = chinese_transformed_theta + english_transformed_theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------FITTING MODELS-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0284s.) Setting batch_size=14.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of  11 | elapsed:    0.1s remaining:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of  11 | elapsed:    0.1s remaining:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of  11 | elapsed:    0.2s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done   8 out of  11 | elapsed:    0.2s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  11 out of  11 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------SCORING MODELS-------------\n",
      "This model/metric cannot use predict_proba. Using predict for scoring instead.\n",
      "This model/metric cannot use predict_proba. Using predict for scoring instead.\n",
      "This model/metric cannot use predict_proba. Using predict for scoring instead.\n",
      "This model/metric cannot use predict_proba. Using predict for scoring instead.\n",
      "This model/metric cannot use predict_proba. Using predict for scoring instead.\n",
      "This model/metric cannot use predict_proba. Using predict for scoring instead.\n",
      "This model/metric cannot use predict_proba. Using predict for scoring instead.\n",
      "This model/metric cannot use predict_proba. Using predict for scoring instead.\n",
      "This model/metric cannot use predict_proba. Using predict for scoring instead.\n",
      "This model/metric cannot use predict_proba. Using predict for scoring instead.\n",
      "This model/metric cannot use predict_proba. Using predict for scoring instead.\n",
      "0.43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   8 out of  11 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  11 out of  11 | elapsed:    0.1s finished\n"
     ]
    }
   ],
   "source": [
    "# Corpus load back and  describe class column\n",
    "Corpus = pd.read_pickle(\"../out/MLDoc/tagged_englishAndchinese_corpus_pd.pkl\")\n",
    "\n",
    "grid = {\n",
    "    'C': [0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95, 1e0],\n",
    "    'penalty': ['l2'],\n",
    "    'n_jobs': [-1],\n",
    "    'solver': ['lbfgs'],\n",
    "    'multi_class': ['ovr']\n",
    "}\n",
    "\n",
    "paramGrid = ParameterGrid(grid)\n",
    "\n",
    "each_corpus = Corpus.copy()\n",
    "\n",
    "each_corpus[\"theta\"] = PMLDA_theta\n",
    "Data_Object, _ = transform_pd_to_numpy_data(each_corpus, language=\"Chinese\")\n",
    "\n",
    "bestModel, bestScore, _, _ = pf.bestFit(LogisticRegression, paramGrid,\n",
    "           Data_Object[\"x_train\"], Data_Object[\"y_train\"], Data_Object[\"x_dev\"], Data_Object[\"y_dev\"],\n",
    "           metric = accuracy_score, scoreLabel = \"Accuracy\", showPlot=False)\n",
    "\n",
    "acc = bestModel.score(X=Data_Object[\"x_test\"], y=Data_Object[\"y_test\"])\n",
    "print(acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cross-lingual]",
   "language": "python",
   "name": "conda-env-cross-lingual-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

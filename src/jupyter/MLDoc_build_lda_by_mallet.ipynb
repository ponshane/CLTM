{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-01 21:11:10,416 : INFO : 'pattern' package not found; tag filters are not available for English\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Consider to transform this ipynb to py\n",
    "\"\"\"\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s',\\\n",
    "    level=logging.INFO)\n",
    "\n",
    "from gensim import corpora\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build monolingual topic model for MLDoc EN-ZH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-01 21:11:23,245 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-09-01 21:11:23,640 : INFO : adding document #10000 to Dictionary(6753 unique tokens: ['f', 'p', 'r', '上季', '亿第季']...)\n",
      "2020-09-01 21:11:23,838 : INFO : built Dictionary(6760 unique tokens: ['f', 'p', 'r', '上季', '亿第季']...) from 14997 documents (total 1006731 corpus positions)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(6760 unique tokens: ['f', 'p', 'r', '上季', '亿第季']...)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-01 21:11:24,346 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-09-01 21:11:24,828 : INFO : adding document #10000 to Dictionary(12823 unique tokens: ['autumn', 'capacitor', 'company', 'decline', 'electronic']...)\n",
      "2020-09-01 21:11:25,069 : INFO : built Dictionary(14254 unique tokens: ['autumn', 'capacitor', 'company', 'decline', 'electronic']...) from 14997 documents (total 1219305 corpus positions)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(14254 unique tokens: ['autumn', 'capacitor', 'company', 'decline', 'electronic']...)\n",
      "14997 14997\n",
      "CPU times: user 2.49 s, sys: 84.1 ms, total: 2.58 s\n",
      "Wall time: 2.57 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "en_corpus_path = \"/home/ponshane/work_dir/CLTM-Experiments/Data/EN-ZH-MLDoc/MLDoc-English.txt\"\n",
    "zh_corpus_path = \"/home/ponshane/work_dir/CLTM-Experiments/Data/EN-ZH-MLDoc/MLDoc-Chinese.txt\"\n",
    "\n",
    "en_file = open(en_corpus_path, 'r')\n",
    "zh_file = open(zh_corpus_path, 'r')\n",
    "\n",
    "chinese_docs = []\n",
    "english_docs = []\n",
    "\n",
    "for idx, doc in enumerate(en_file.readlines()):\n",
    "    english_docs.append(doc.replace(\"\\n\", \"\").split(\" \"))\n",
    "\n",
    "for idx, doc in enumerate(zh_file.readlines()):\n",
    "    chinese_docs.append(doc.replace(\"\\n\", \"\").split(\" \"))\n",
    "\n",
    "en_file.close()\n",
    "zh_file.close()\n",
    "\n",
    "# turn our tokenized documents into a id <-> cluster_id dictionary\n",
    "chinese_dictionary = corpora.Dictionary(chinese_docs)\n",
    "print(chinese_dictionary)\n",
    "# convert tokenized documents into a document-term matrix\n",
    "chinese_corpus = [chinese_dictionary.doc2bow(text) for text in chinese_docs]\n",
    "\n",
    "# turn our tokenized documents into a id <-> cluster_id dictionary\n",
    "english_dictionary = corpora.Dictionary(english_docs)\n",
    "print(english_dictionary)\n",
    "# convert tokenized documents into a document-term matrix\n",
    "english_corpus = [english_dictionary.doc2bow(text) for text in english_docs]\n",
    "\n",
    "print(len(chinese_corpus), len(english_corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29994"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chinese_corpus) + len(english_corpus)\n",
    "# check this number with tag_labels_on_docs.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-01 21:12:27,160 : INFO : serializing temporary corpus to /tmp/fbcd4a_corpus.txt\n",
      "2020-09-01 21:12:27,711 : INFO : converting temporary corpus to MALLET format with /home/ponshane/work_dir/Mallet/bin/mallet import-file --preserve-case --keep-sequence --remove-stopwords --token-regex \"\\S+\" --input /tmp/fbcd4a_corpus.txt --output /tmp/fbcd4a_corpus.mallet\n",
      "2020-09-01 21:12:28,497 : INFO : training MALLET LDA with /home/ponshane/work_dir/Mallet/bin/mallet train-topics --input /tmp/fbcd4a_corpus.mallet --num-topics 10  --alpha 0.1 --optimize-interval 0 --num-threads 4 --output-state /tmp/fbcd4a_state.mallet.gz --output-doc-topics /tmp/fbcd4a_doctopics.txt --output-topic-keys /tmp/fbcd4a_topickeys.txt --num-iterations 1000 --inferencer-filename /tmp/fbcd4a_inferencer.mallet --doc-topics-threshold 0.0\n",
      "2020-09-01 21:13:06,364 : INFO : loading assigned topics from /tmp/fbcd4a_state.mallet.gz\n",
      "2020-09-01 21:13:08,803 : INFO : serializing temporary corpus to /tmp/6f828c_corpus.txt\n",
      "2020-09-01 21:13:09,518 : INFO : converting temporary corpus to MALLET format with /home/ponshane/work_dir/Mallet/bin/mallet import-file --preserve-case --keep-sequence --remove-stopwords --token-regex \"\\S+\" --input /tmp/6f828c_corpus.txt --output /tmp/6f828c_corpus.mallet\n",
      "2020-09-01 21:13:10,436 : INFO : training MALLET LDA with /home/ponshane/work_dir/Mallet/bin/mallet train-topics --input /tmp/6f828c_corpus.mallet --num-topics 10  --alpha 0.1 --optimize-interval 0 --num-threads 4 --output-state /tmp/6f828c_state.mallet.gz --output-doc-topics /tmp/6f828c_doctopics.txt --output-topic-keys /tmp/6f828c_topickeys.txt --num-iterations 1000 --inferencer-filename /tmp/6f828c_inferencer.mallet --doc-topics-threshold 0.0\n",
      "2020-09-01 21:14:12,658 : INFO : loading assigned topics from /tmp/6f828c_state.mallet.gz\n",
      "2020-09-01 21:14:15,168 : INFO : saving LdaMallet object under /home/ponshane/work_dir/CLTM-Experiments/Data/EN-ZH-MLDoc/monolingual-lda/10topics-cn.model, separately None\n",
      "2020-09-01 21:14:15,174 : INFO : saved /home/ponshane/work_dir/CLTM-Experiments/Data/EN-ZH-MLDoc/monolingual-lda/10topics-cn.model\n",
      "2020-09-01 21:14:15,175 : INFO : saving LdaMallet object under /home/ponshane/work_dir/CLTM-Experiments/Data/EN-ZH-MLDoc/monolingual-lda/10topics-en.model, separately None\n",
      "2020-09-01 21:14:15,187 : INFO : saved /home/ponshane/work_dir/CLTM-Experiments/Data/EN-ZH-MLDoc/monolingual-lda/10topics-en.model\n",
      "2020-09-01 21:14:15,188 : INFO : serializing temporary corpus to /tmp/d17f54_corpus.txt\n",
      "2020-09-01 21:14:15,754 : INFO : converting temporary corpus to MALLET format with /home/ponshane/work_dir/Mallet/bin/mallet import-file --preserve-case --keep-sequence --remove-stopwords --token-regex \"\\S+\" --input /tmp/d17f54_corpus.txt --output /tmp/d17f54_corpus.mallet\n",
      "2020-09-01 21:14:16,534 : INFO : training MALLET LDA with /home/ponshane/work_dir/Mallet/bin/mallet train-topics --input /tmp/d17f54_corpus.mallet --num-topics 20  --alpha 0.1 --optimize-interval 0 --num-threads 4 --output-state /tmp/d17f54_state.mallet.gz --output-doc-topics /tmp/d17f54_doctopics.txt --output-topic-keys /tmp/d17f54_topickeys.txt --num-iterations 1000 --inferencer-filename /tmp/d17f54_inferencer.mallet --doc-topics-threshold 0.0\n",
      "2020-09-01 21:15:03,989 : INFO : loading assigned topics from /tmp/d17f54_state.mallet.gz\n",
      "2020-09-01 21:15:06,419 : INFO : serializing temporary corpus to /tmp/6078df_corpus.txt\n",
      "2020-09-01 21:15:07,092 : INFO : converting temporary corpus to MALLET format with /home/ponshane/work_dir/Mallet/bin/mallet import-file --preserve-case --keep-sequence --remove-stopwords --token-regex \"\\S+\" --input /tmp/6078df_corpus.txt --output /tmp/6078df_corpus.mallet\n",
      "2020-09-01 21:15:08,045 : INFO : training MALLET LDA with /home/ponshane/work_dir/Mallet/bin/mallet train-topics --input /tmp/6078df_corpus.mallet --num-topics 20  --alpha 0.1 --optimize-interval 0 --num-threads 4 --output-state /tmp/6078df_state.mallet.gz --output-doc-topics /tmp/6078df_doctopics.txt --output-topic-keys /tmp/6078df_topickeys.txt --num-iterations 1000 --inferencer-filename /tmp/6078df_inferencer.mallet --doc-topics-threshold 0.0\n",
      "2020-09-01 21:15:58,470 : INFO : loading assigned topics from /tmp/6078df_state.mallet.gz\n",
      "2020-09-01 21:16:00,907 : INFO : saving LdaMallet object under /home/ponshane/work_dir/CLTM-Experiments/Data/EN-ZH-MLDoc/monolingual-lda/20topics-cn.model, separately None\n",
      "2020-09-01 21:16:00,915 : INFO : saved /home/ponshane/work_dir/CLTM-Experiments/Data/EN-ZH-MLDoc/monolingual-lda/20topics-cn.model\n",
      "2020-09-01 21:16:00,915 : INFO : saving LdaMallet object under /home/ponshane/work_dir/CLTM-Experiments/Data/EN-ZH-MLDoc/monolingual-lda/20topics-en.model, separately None\n",
      "2020-09-01 21:16:00,929 : INFO : saved /home/ponshane/work_dir/CLTM-Experiments/Data/EN-ZH-MLDoc/monolingual-lda/20topics-en.model\n",
      "2020-09-01 21:16:00,930 : INFO : serializing temporary corpus to /tmp/c7df16_corpus.txt\n",
      "2020-09-01 21:16:01,504 : INFO : converting temporary corpus to MALLET format with /home/ponshane/work_dir/Mallet/bin/mallet import-file --preserve-case --keep-sequence --remove-stopwords --token-regex \"\\S+\" --input /tmp/c7df16_corpus.txt --output /tmp/c7df16_corpus.mallet\n",
      "2020-09-01 21:16:02,301 : INFO : training MALLET LDA with /home/ponshane/work_dir/Mallet/bin/mallet train-topics --input /tmp/c7df16_corpus.mallet --num-topics 30  --alpha 0.1 --optimize-interval 0 --num-threads 4 --output-state /tmp/c7df16_state.mallet.gz --output-doc-topics /tmp/c7df16_doctopics.txt --output-topic-keys /tmp/c7df16_topickeys.txt --num-iterations 1000 --inferencer-filename /tmp/c7df16_inferencer.mallet --doc-topics-threshold 0.0\n",
      "2020-09-01 21:16:51,995 : INFO : loading assigned topics from /tmp/c7df16_state.mallet.gz\n",
      "2020-09-01 21:16:54,436 : INFO : serializing temporary corpus to /tmp/ae2abc_corpus.txt\n",
      "2020-09-01 21:16:55,111 : INFO : converting temporary corpus to MALLET format with /home/ponshane/work_dir/Mallet/bin/mallet import-file --preserve-case --keep-sequence --remove-stopwords --token-regex \"\\S+\" --input /tmp/ae2abc_corpus.txt --output /tmp/ae2abc_corpus.mallet\n",
      "2020-09-01 21:16:56,024 : INFO : training MALLET LDA with /home/ponshane/work_dir/Mallet/bin/mallet train-topics --input /tmp/ae2abc_corpus.mallet --num-topics 30  --alpha 0.1 --optimize-interval 0 --num-threads 4 --output-state /tmp/ae2abc_state.mallet.gz --output-doc-topics /tmp/ae2abc_doctopics.txt --output-topic-keys /tmp/ae2abc_topickeys.txt --num-iterations 1000 --inferencer-filename /tmp/ae2abc_inferencer.mallet --doc-topics-threshold 0.0\n",
      "2020-09-01 21:17:49,559 : INFO : loading assigned topics from /tmp/ae2abc_state.mallet.gz\n",
      "2020-09-01 21:17:52,020 : INFO : saving LdaMallet object under /home/ponshane/work_dir/CLTM-Experiments/Data/EN-ZH-MLDoc/monolingual-lda/30topics-cn.model, separately None\n",
      "2020-09-01 21:17:52,028 : INFO : saved /home/ponshane/work_dir/CLTM-Experiments/Data/EN-ZH-MLDoc/monolingual-lda/30topics-cn.model\n",
      "2020-09-01 21:17:52,029 : INFO : saving LdaMallet object under /home/ponshane/work_dir/CLTM-Experiments/Data/EN-ZH-MLDoc/monolingual-lda/30topics-en.model, separately None\n",
      "2020-09-01 21:17:52,046 : INFO : saved /home/ponshane/work_dir/CLTM-Experiments/Data/EN-ZH-MLDoc/monolingual-lda/30topics-en.model\n",
      "2020-09-01 21:17:52,047 : INFO : serializing temporary corpus to /tmp/cb448_corpus.txt\n",
      "2020-09-01 21:17:52,602 : INFO : converting temporary corpus to MALLET format with /home/ponshane/work_dir/Mallet/bin/mallet import-file --preserve-case --keep-sequence --remove-stopwords --token-regex \"\\S+\" --input /tmp/cb448_corpus.txt --output /tmp/cb448_corpus.mallet\n",
      "2020-09-01 21:17:53,385 : INFO : training MALLET LDA with /home/ponshane/work_dir/Mallet/bin/mallet train-topics --input /tmp/cb448_corpus.mallet --num-topics 40  --alpha 0.1 --optimize-interval 0 --num-threads 4 --output-state /tmp/cb448_state.mallet.gz --output-doc-topics /tmp/cb448_doctopics.txt --output-topic-keys /tmp/cb448_topickeys.txt --num-iterations 1000 --inferencer-filename /tmp/cb448_inferencer.mallet --doc-topics-threshold 0.0\n",
      "2020-09-01 21:18:45,049 : INFO : loading assigned topics from /tmp/cb448_state.mallet.gz\n",
      "2020-09-01 21:18:47,488 : INFO : serializing temporary corpus to /tmp/2d5908_corpus.txt\n",
      "2020-09-01 21:18:48,189 : INFO : converting temporary corpus to MALLET format with /home/ponshane/work_dir/Mallet/bin/mallet import-file --preserve-case --keep-sequence --remove-stopwords --token-regex \"\\S+\" --input /tmp/2d5908_corpus.txt --output /tmp/2d5908_corpus.mallet\n",
      "2020-09-01 21:18:49,108 : INFO : training MALLET LDA with /home/ponshane/work_dir/Mallet/bin/mallet train-topics --input /tmp/2d5908_corpus.mallet --num-topics 40  --alpha 0.1 --optimize-interval 0 --num-threads 4 --output-state /tmp/2d5908_state.mallet.gz --output-doc-topics /tmp/2d5908_doctopics.txt --output-topic-keys /tmp/2d5908_topickeys.txt --num-iterations 1000 --inferencer-filename /tmp/2d5908_inferencer.mallet --doc-topics-threshold 0.0\n",
      "2020-09-01 21:19:51,893 : INFO : loading assigned topics from /tmp/2d5908_state.mallet.gz\n",
      "2020-09-01 21:19:54,350 : INFO : saving LdaMallet object under /home/ponshane/work_dir/CLTM-Experiments/Data/EN-ZH-MLDoc/monolingual-lda/40topics-cn.model, separately None\n",
      "2020-09-01 21:19:54,360 : INFO : saved /home/ponshane/work_dir/CLTM-Experiments/Data/EN-ZH-MLDoc/monolingual-lda/40topics-cn.model\n",
      "2020-09-01 21:19:54,361 : INFO : saving LdaMallet object under /home/ponshane/work_dir/CLTM-Experiments/Data/EN-ZH-MLDoc/monolingual-lda/40topics-en.model, separately None\n",
      "2020-09-01 21:19:54,381 : INFO : saved /home/ponshane/work_dir/CLTM-Experiments/Data/EN-ZH-MLDoc/monolingual-lda/40topics-en.model\n",
      "2020-09-01 21:19:54,382 : INFO : serializing temporary corpus to /tmp/67639c_corpus.txt\n",
      "2020-09-01 21:19:54,966 : INFO : converting temporary corpus to MALLET format with /home/ponshane/work_dir/Mallet/bin/mallet import-file --preserve-case --keep-sequence --remove-stopwords --token-regex \"\\S+\" --input /tmp/67639c_corpus.txt --output /tmp/67639c_corpus.mallet\n",
      "2020-09-01 21:19:55,764 : INFO : training MALLET LDA with /home/ponshane/work_dir/Mallet/bin/mallet train-topics --input /tmp/67639c_corpus.mallet --num-topics 50  --alpha 0.1 --optimize-interval 0 --num-threads 4 --output-state /tmp/67639c_state.mallet.gz --output-doc-topics /tmp/67639c_doctopics.txt --output-topic-keys /tmp/67639c_topickeys.txt --num-iterations 1000 --inferencer-filename /tmp/67639c_inferencer.mallet --doc-topics-threshold 0.0\n",
      "2020-09-01 21:20:49,108 : INFO : loading assigned topics from /tmp/67639c_state.mallet.gz\n",
      "2020-09-01 21:20:51,524 : INFO : serializing temporary corpus to /tmp/c38261_corpus.txt\n",
      "2020-09-01 21:20:52,173 : INFO : converting temporary corpus to MALLET format with /home/ponshane/work_dir/Mallet/bin/mallet import-file --preserve-case --keep-sequence --remove-stopwords --token-regex \"\\S+\" --input /tmp/c38261_corpus.txt --output /tmp/c38261_corpus.mallet\n",
      "2020-09-01 21:20:53,110 : INFO : training MALLET LDA with /home/ponshane/work_dir/Mallet/bin/mallet train-topics --input /tmp/c38261_corpus.mallet --num-topics 50  --alpha 0.1 --optimize-interval 0 --num-threads 4 --output-state /tmp/c38261_state.mallet.gz --output-doc-topics /tmp/c38261_doctopics.txt --output-topic-keys /tmp/c38261_topickeys.txt --num-iterations 1000 --inferencer-filename /tmp/c38261_inferencer.mallet --doc-topics-threshold 0.0\n",
      "2020-09-01 21:21:57,830 : INFO : loading assigned topics from /tmp/c38261_state.mallet.gz\n",
      "2020-09-01 21:22:00,294 : INFO : saving LdaMallet object under /home/ponshane/work_dir/CLTM-Experiments/Data/EN-ZH-MLDoc/monolingual-lda/50topics-cn.model, separately None\n",
      "2020-09-01 21:22:00,305 : INFO : saved /home/ponshane/work_dir/CLTM-Experiments/Data/EN-ZH-MLDoc/monolingual-lda/50topics-cn.model\n",
      "2020-09-01 21:22:00,306 : INFO : saving LdaMallet object under /home/ponshane/work_dir/CLTM-Experiments/Data/EN-ZH-MLDoc/monolingual-lda/50topics-en.model, separately None\n",
      "2020-09-01 21:22:00,327 : INFO : saved /home/ponshane/work_dir/CLTM-Experiments/Data/EN-ZH-MLDoc/monolingual-lda/50topics-en.model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 30.9 s, sys: 355 ms, total: 31.2 s\n",
      "Wall time: 9min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "path_of_mallet = \"/home/ponshane/work_dir/Mallet/bin/mallet\"\n",
    "\n",
    "topic_nums = [10, 20, 30, 40, 50]\n",
    "\n",
    "for topic in topic_nums:\n",
    "    \n",
    "    chinese_model = gensim.models.wrappers.LdaMallet(path_of_mallet, corpus=chinese_corpus, num_topics=topic,\n",
    "                                                 id2word=chinese_dictionary, optimize_interval = 0, alpha = 0.1,\n",
    "                                                 iterations= 1000)\n",
    "    english_model = gensim.models.wrappers.LdaMallet(path_of_mallet, corpus=english_corpus, num_topics=topic,\n",
    "                                                 id2word=english_dictionary, optimize_interval = 0, alpha = 0.1,\n",
    "                                                 iterations= 1000)\n",
    "    \n",
    "    chinese_model.save(\"/home/ponshane/work_dir/CLTM-Experiments/Data/EN-ZH-MLDoc/monolingual-lda/\"+str(topic)+\"topics-cn.model\")\n",
    "    english_model.save(\"/home/ponshane/work_dir/CLTM-Experiments/Data/EN-ZH-MLDoc/monolingual-lda/\"+str(topic)+\"topics-en.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build monolingual topic model for MLDoc EN-JP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-01 21:26:13,446 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-09-01 21:26:13,932 : INFO : adding document #10000 to Dictionary(12523 unique tokens: ['あまり', 'あり', 'ある', 'あれ', 'いう']...)\n",
      "2020-09-01 21:26:14,183 : INFO : built Dictionary(12800 unique tokens: ['あまり', 'あり', 'ある', 'あれ', 'いう']...) from 15000 documents (total 1236686 corpus positions)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(12800 unique tokens: ['あまり', 'あり', 'ある', 'あれ', 'いう']...)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-01 21:26:14,749 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-09-01 21:26:15,224 : INFO : adding document #10000 to Dictionary(12777 unique tokens: ['add', 'month', 'newsroom', 'percent', 'quarter']...)\n",
      "2020-09-01 21:26:15,465 : INFO : built Dictionary(14254 unique tokens: ['add', 'month', 'newsroom', 'percent', 'quarter']...) from 14997 documents (total 1219305 corpus positions)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(14254 unique tokens: ['add', 'month', 'newsroom', 'percent', 'quarter']...)\n",
      "15000 14997\n",
      "CPU times: user 2.99 s, sys: 28 ms, total: 3.02 s\n",
      "Wall time: 3.01 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "en_corpus_path = \"/home/ponshane/work_dir/CLTM-Experiments/Data/EN-JP-MLDoc/MLDoc-English.txt\"\n",
    "jp_corpus_path = \"/home/ponshane/work_dir/CLTM-Experiments/Data/EN-JP-MLDoc/MLDoc-Jpanese.txt\"\n",
    "\n",
    "en_file = open(en_corpus_path, 'r')\n",
    "jp_file = open(jp_corpus_path, 'r')\n",
    "\n",
    "japanese_docs = []\n",
    "english_docs = []\n",
    "\n",
    "for idx, doc in enumerate(en_file.readlines()):\n",
    "    english_docs.append(doc.replace(\"\\n\", \"\").split(\" \"))\n",
    "\n",
    "for idx, doc in enumerate(jp_file.readlines()):\n",
    "    japanese_docs.append(doc.replace(\"\\n\", \"\").split(\" \"))\n",
    "\n",
    "en_file.close()\n",
    "jp_file.close()\n",
    "\n",
    "# turn our tokenized documents into a id <-> cluster_id dictionary\n",
    "japanese_dictionary = corpora.Dictionary(japanese_docs)\n",
    "print(japanese_dictionary)\n",
    "# convert tokenized documents into a document-term matrix\n",
    "japanese_corpus = [japanese_dictionary.doc2bow(text) for text in japanese_docs]\n",
    "\n",
    "# turn our tokenized documents into a id <-> cluster_id dictionary\n",
    "english_dictionary = corpora.Dictionary(english_docs)\n",
    "print(english_dictionary)\n",
    "# convert tokenized documents into a document-term matrix\n",
    "english_corpus = [english_dictionary.doc2bow(text) for text in english_docs]\n",
    "\n",
    "print(len(japanese_corpus), len(english_corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29997"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(japanese_corpus) + len(english_corpus)\n",
    "# check this number with tag_labels_on_docs.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-01 21:26:51,399 : INFO : serializing temporary corpus to /tmp/325fdd_corpus.txt\n",
      "2020-09-01 21:26:52,109 : INFO : converting temporary corpus to MALLET format with /home/ponshane/work_dir/Mallet/bin/mallet import-file --preserve-case --keep-sequence --remove-stopwords --token-regex \"\\S+\" --input /tmp/325fdd_corpus.txt --output /tmp/325fdd_corpus.mallet\n",
      "2020-09-01 21:26:53,001 : INFO : training MALLET LDA with /home/ponshane/work_dir/Mallet/bin/mallet train-topics --input /tmp/325fdd_corpus.mallet --num-topics 10  --alpha 0.1 --optimize-interval 0 --num-threads 4 --output-state /tmp/325fdd_state.mallet.gz --output-doc-topics /tmp/325fdd_doctopics.txt --output-topic-keys /tmp/325fdd_topickeys.txt --num-iterations 1000 --inferencer-filename /tmp/325fdd_inferencer.mallet --doc-topics-threshold 0.0\n",
      "2020-09-01 21:27:41,963 : INFO : loading assigned topics from /tmp/325fdd_state.mallet.gz\n",
      "2020-09-01 21:27:45,016 : INFO : serializing temporary corpus to /tmp/e57b5c_corpus.txt\n",
      "2020-09-01 21:27:45,708 : INFO : converting temporary corpus to MALLET format with /home/ponshane/work_dir/Mallet/bin/mallet import-file --preserve-case --keep-sequence --remove-stopwords --token-regex \"\\S+\" --input /tmp/e57b5c_corpus.txt --output /tmp/e57b5c_corpus.mallet\n",
      "2020-09-01 21:27:46,648 : INFO : training MALLET LDA with /home/ponshane/work_dir/Mallet/bin/mallet train-topics --input /tmp/e57b5c_corpus.mallet --num-topics 10  --alpha 0.1 --optimize-interval 0 --num-threads 4 --output-state /tmp/e57b5c_state.mallet.gz --output-doc-topics /tmp/e57b5c_doctopics.txt --output-topic-keys /tmp/e57b5c_topickeys.txt --num-iterations 1000 --inferencer-filename /tmp/e57b5c_inferencer.mallet --doc-topics-threshold 0.0\n",
      "2020-09-01 21:28:33,742 : INFO : loading assigned topics from /tmp/e57b5c_state.mallet.gz\n",
      "2020-09-01 21:28:36,208 : INFO : saving LdaMallet object under /home/ponshane/work_dir/CLTM-Experiments/Data/EN-JP-MLDoc/monolingual-lda/10topics-jp.model, separately None\n",
      "2020-09-01 21:28:36,220 : INFO : saved /home/ponshane/work_dir/CLTM-Experiments/Data/EN-JP-MLDoc/monolingual-lda/10topics-jp.model\n",
      "2020-09-01 21:28:36,220 : INFO : saving LdaMallet object under /home/ponshane/work_dir/CLTM-Experiments/Data/EN-JP-MLDoc/monolingual-lda/10topics-en.model, separately None\n",
      "2020-09-01 21:28:36,229 : INFO : saved /home/ponshane/work_dir/CLTM-Experiments/Data/EN-JP-MLDoc/monolingual-lda/10topics-en.model\n",
      "2020-09-01 21:28:36,229 : INFO : serializing temporary corpus to /tmp/6ed42e_corpus.txt\n",
      "2020-09-01 21:28:36,951 : INFO : converting temporary corpus to MALLET format with /home/ponshane/work_dir/Mallet/bin/mallet import-file --preserve-case --keep-sequence --remove-stopwords --token-regex \"\\S+\" --input /tmp/6ed42e_corpus.txt --output /tmp/6ed42e_corpus.mallet\n",
      "2020-09-01 21:28:37,842 : INFO : training MALLET LDA with /home/ponshane/work_dir/Mallet/bin/mallet train-topics --input /tmp/6ed42e_corpus.mallet --num-topics 20  --alpha 0.1 --optimize-interval 0 --num-threads 4 --output-state /tmp/6ed42e_state.mallet.gz --output-doc-topics /tmp/6ed42e_doctopics.txt --output-topic-keys /tmp/6ed42e_topickeys.txt --num-iterations 1000 --inferencer-filename /tmp/6ed42e_inferencer.mallet --doc-topics-threshold 0.0\n",
      "2020-09-01 21:29:29,173 : INFO : loading assigned topics from /tmp/6ed42e_state.mallet.gz\n",
      "2020-09-01 21:29:32,276 : INFO : serializing temporary corpus to /tmp/aaf3cb_corpus.txt\n",
      "2020-09-01 21:29:32,924 : INFO : converting temporary corpus to MALLET format with /home/ponshane/work_dir/Mallet/bin/mallet import-file --preserve-case --keep-sequence --remove-stopwords --token-regex \"\\S+\" --input /tmp/aaf3cb_corpus.txt --output /tmp/aaf3cb_corpus.mallet\n",
      "2020-09-01 21:29:33,881 : INFO : training MALLET LDA with /home/ponshane/work_dir/Mallet/bin/mallet train-topics --input /tmp/aaf3cb_corpus.mallet --num-topics 20  --alpha 0.1 --optimize-interval 0 --num-threads 4 --output-state /tmp/aaf3cb_state.mallet.gz --output-doc-topics /tmp/aaf3cb_doctopics.txt --output-topic-keys /tmp/aaf3cb_topickeys.txt --num-iterations 1000 --inferencer-filename /tmp/aaf3cb_inferencer.mallet --doc-topics-threshold 0.0\n",
      "2020-09-01 21:30:24,583 : INFO : loading assigned topics from /tmp/aaf3cb_state.mallet.gz\n",
      "2020-09-01 21:30:27,244 : INFO : saving LdaMallet object under /home/ponshane/work_dir/CLTM-Experiments/Data/EN-JP-MLDoc/monolingual-lda/20topics-jp.model, separately None\n",
      "2020-09-01 21:30:27,258 : INFO : saved /home/ponshane/work_dir/CLTM-Experiments/Data/EN-JP-MLDoc/monolingual-lda/20topics-jp.model\n",
      "2020-09-01 21:30:27,258 : INFO : saving LdaMallet object under /home/ponshane/work_dir/CLTM-Experiments/Data/EN-JP-MLDoc/monolingual-lda/20topics-en.model, separately None\n",
      "2020-09-01 21:30:27,271 : INFO : saved /home/ponshane/work_dir/CLTM-Experiments/Data/EN-JP-MLDoc/monolingual-lda/20topics-en.model\n",
      "2020-09-01 21:30:27,272 : INFO : serializing temporary corpus to /tmp/3d0e2_corpus.txt\n",
      "2020-09-01 21:30:27,999 : INFO : converting temporary corpus to MALLET format with /home/ponshane/work_dir/Mallet/bin/mallet import-file --preserve-case --keep-sequence --remove-stopwords --token-regex \"\\S+\" --input /tmp/3d0e2_corpus.txt --output /tmp/3d0e2_corpus.mallet\n",
      "2020-09-01 21:30:28,867 : INFO : training MALLET LDA with /home/ponshane/work_dir/Mallet/bin/mallet train-topics --input /tmp/3d0e2_corpus.mallet --num-topics 30  --alpha 0.1 --optimize-interval 0 --num-threads 4 --output-state /tmp/3d0e2_state.mallet.gz --output-doc-topics /tmp/3d0e2_doctopics.txt --output-topic-keys /tmp/3d0e2_topickeys.txt --num-iterations 1000 --inferencer-filename /tmp/3d0e2_inferencer.mallet --doc-topics-threshold 0.0\n",
      "2020-09-01 21:31:30,043 : INFO : loading assigned topics from /tmp/3d0e2_state.mallet.gz\n",
      "2020-09-01 21:31:33,111 : INFO : serializing temporary corpus to /tmp/77a467_corpus.txt\n",
      "2020-09-01 21:31:33,792 : INFO : converting temporary corpus to MALLET format with /home/ponshane/work_dir/Mallet/bin/mallet import-file --preserve-case --keep-sequence --remove-stopwords --token-regex \"\\S+\" --input /tmp/77a467_corpus.txt --output /tmp/77a467_corpus.mallet\n",
      "2020-09-01 21:31:34,775 : INFO : training MALLET LDA with /home/ponshane/work_dir/Mallet/bin/mallet train-topics --input /tmp/77a467_corpus.mallet --num-topics 30  --alpha 0.1 --optimize-interval 0 --num-threads 4 --output-state /tmp/77a467_state.mallet.gz --output-doc-topics /tmp/77a467_doctopics.txt --output-topic-keys /tmp/77a467_topickeys.txt --num-iterations 1000 --inferencer-filename /tmp/77a467_inferencer.mallet --doc-topics-threshold 0.0\n",
      "2020-09-01 21:32:28,307 : INFO : loading assigned topics from /tmp/77a467_state.mallet.gz\n",
      "2020-09-01 21:32:30,866 : INFO : saving LdaMallet object under /home/ponshane/work_dir/CLTM-Experiments/Data/EN-JP-MLDoc/monolingual-lda/30topics-jp.model, separately None\n",
      "2020-09-01 21:32:30,882 : INFO : saved /home/ponshane/work_dir/CLTM-Experiments/Data/EN-JP-MLDoc/monolingual-lda/30topics-jp.model\n",
      "2020-09-01 21:32:30,882 : INFO : saving LdaMallet object under /home/ponshane/work_dir/CLTM-Experiments/Data/EN-JP-MLDoc/monolingual-lda/30topics-en.model, separately None\n",
      "2020-09-01 21:32:30,899 : INFO : saved /home/ponshane/work_dir/CLTM-Experiments/Data/EN-JP-MLDoc/monolingual-lda/30topics-en.model\n",
      "2020-09-01 21:32:30,900 : INFO : serializing temporary corpus to /tmp/75ba2a_corpus.txt\n",
      "2020-09-01 21:32:31,610 : INFO : converting temporary corpus to MALLET format with /home/ponshane/work_dir/Mallet/bin/mallet import-file --preserve-case --keep-sequence --remove-stopwords --token-regex \"\\S+\" --input /tmp/75ba2a_corpus.txt --output /tmp/75ba2a_corpus.mallet\n",
      "2020-09-01 21:32:32,494 : INFO : training MALLET LDA with /home/ponshane/work_dir/Mallet/bin/mallet train-topics --input /tmp/75ba2a_corpus.mallet --num-topics 40  --alpha 0.1 --optimize-interval 0 --num-threads 4 --output-state /tmp/75ba2a_state.mallet.gz --output-doc-topics /tmp/75ba2a_doctopics.txt --output-topic-keys /tmp/75ba2a_topickeys.txt --num-iterations 1000 --inferencer-filename /tmp/75ba2a_inferencer.mallet --doc-topics-threshold 0.0\n",
      "2020-09-01 21:33:36,828 : INFO : loading assigned topics from /tmp/75ba2a_state.mallet.gz\n",
      "2020-09-01 21:33:39,946 : INFO : serializing temporary corpus to /tmp/585ed3_corpus.txt\n",
      "2020-09-01 21:33:40,605 : INFO : converting temporary corpus to MALLET format with /home/ponshane/work_dir/Mallet/bin/mallet import-file --preserve-case --keep-sequence --remove-stopwords --token-regex \"\\S+\" --input /tmp/585ed3_corpus.txt --output /tmp/585ed3_corpus.mallet\n",
      "2020-09-01 21:33:41,546 : INFO : training MALLET LDA with /home/ponshane/work_dir/Mallet/bin/mallet train-topics --input /tmp/585ed3_corpus.mallet --num-topics 40  --alpha 0.1 --optimize-interval 0 --num-threads 4 --output-state /tmp/585ed3_state.mallet.gz --output-doc-topics /tmp/585ed3_doctopics.txt --output-topic-keys /tmp/585ed3_topickeys.txt --num-iterations 1000 --inferencer-filename /tmp/585ed3_inferencer.mallet --doc-topics-threshold 0.0\n",
      "2020-09-01 21:34:45,596 : INFO : loading assigned topics from /tmp/585ed3_state.mallet.gz\n",
      "2020-09-01 21:34:48,124 : INFO : saving LdaMallet object under /home/ponshane/work_dir/CLTM-Experiments/Data/EN-JP-MLDoc/monolingual-lda/40topics-jp.model, separately None\n",
      "2020-09-01 21:34:48,142 : INFO : saved /home/ponshane/work_dir/CLTM-Experiments/Data/EN-JP-MLDoc/monolingual-lda/40topics-jp.model\n",
      "2020-09-01 21:34:48,142 : INFO : saving LdaMallet object under /home/ponshane/work_dir/CLTM-Experiments/Data/EN-JP-MLDoc/monolingual-lda/40topics-en.model, separately None\n",
      "2020-09-01 21:34:48,160 : INFO : saved /home/ponshane/work_dir/CLTM-Experiments/Data/EN-JP-MLDoc/monolingual-lda/40topics-en.model\n",
      "2020-09-01 21:34:48,161 : INFO : serializing temporary corpus to /tmp/e59c61_corpus.txt\n",
      "2020-09-01 21:34:48,875 : INFO : converting temporary corpus to MALLET format with /home/ponshane/work_dir/Mallet/bin/mallet import-file --preserve-case --keep-sequence --remove-stopwords --token-regex \"\\S+\" --input /tmp/e59c61_corpus.txt --output /tmp/e59c61_corpus.mallet\n",
      "2020-09-01 21:34:49,763 : INFO : training MALLET LDA with /home/ponshane/work_dir/Mallet/bin/mallet train-topics --input /tmp/e59c61_corpus.mallet --num-topics 50  --alpha 0.1 --optimize-interval 0 --num-threads 4 --output-state /tmp/e59c61_state.mallet.gz --output-doc-topics /tmp/e59c61_doctopics.txt --output-topic-keys /tmp/e59c61_topickeys.txt --num-iterations 1000 --inferencer-filename /tmp/e59c61_inferencer.mallet --doc-topics-threshold 0.0\n",
      "2020-09-01 21:36:03,857 : INFO : loading assigned topics from /tmp/e59c61_state.mallet.gz\n",
      "2020-09-01 21:36:06,977 : INFO : serializing temporary corpus to /tmp/d210a5_corpus.txt\n",
      "2020-09-01 21:36:07,628 : INFO : converting temporary corpus to MALLET format with /home/ponshane/work_dir/Mallet/bin/mallet import-file --preserve-case --keep-sequence --remove-stopwords --token-regex \"\\S+\" --input /tmp/d210a5_corpus.txt --output /tmp/d210a5_corpus.mallet\n",
      "2020-09-01 21:36:08,554 : INFO : training MALLET LDA with /home/ponshane/work_dir/Mallet/bin/mallet train-topics --input /tmp/d210a5_corpus.mallet --num-topics 50  --alpha 0.1 --optimize-interval 0 --num-threads 4 --output-state /tmp/d210a5_state.mallet.gz --output-doc-topics /tmp/d210a5_doctopics.txt --output-topic-keys /tmp/d210a5_topickeys.txt --num-iterations 1000 --inferencer-filename /tmp/d210a5_inferencer.mallet --doc-topics-threshold 0.0\n",
      "2020-09-01 21:37:13,270 : INFO : loading assigned topics from /tmp/d210a5_state.mallet.gz\n",
      "2020-09-01 21:37:15,880 : INFO : saving LdaMallet object under /home/ponshane/work_dir/CLTM-Experiments/Data/EN-JP-MLDoc/monolingual-lda/50topics-jp.model, separately None\n",
      "2020-09-01 21:37:15,901 : INFO : saved /home/ponshane/work_dir/CLTM-Experiments/Data/EN-JP-MLDoc/monolingual-lda/50topics-jp.model\n",
      "2020-09-01 21:37:15,901 : INFO : saving LdaMallet object under /home/ponshane/work_dir/CLTM-Experiments/Data/EN-JP-MLDoc/monolingual-lda/50topics-en.model, separately None\n",
      "2020-09-01 21:37:15,922 : INFO : saved /home/ponshane/work_dir/CLTM-Experiments/Data/EN-JP-MLDoc/monolingual-lda/50topics-en.model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 35.3 s, sys: 393 ms, total: 35.7 s\n",
      "Wall time: 10min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "path_of_mallet = \"/home/ponshane/work_dir/Mallet/bin/mallet\"\n",
    "\n",
    "topic_nums = [10, 20, 30, 40, 50]\n",
    "\n",
    "for topic in topic_nums:\n",
    "    \n",
    "    japanese_model = gensim.models.wrappers.LdaMallet(path_of_mallet, corpus=japanese_corpus, num_topics=topic,\n",
    "                                                 id2word=japanese_dictionary, optimize_interval = 0, alpha = 0.1,\n",
    "                                                 iterations= 1000)\n",
    "    english_model = gensim.models.wrappers.LdaMallet(path_of_mallet, corpus=english_corpus, num_topics=topic,\n",
    "                                                 id2word=english_dictionary, optimize_interval = 0, alpha = 0.1,\n",
    "                                                 iterations= 1000)\n",
    "    \n",
    "    japanese_model.save(\"/home/ponshane/work_dir/CLTM-Experiments/Data/EN-JP-MLDoc/monolingual-lda/\"+str(topic)+\"topics-jp.model\")\n",
    "    english_model.save(\"/home/ponshane/work_dir/CLTM-Experiments/Data/EN-JP-MLDoc/monolingual-lda/\"+str(topic)+\"topics-en.model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cross-lingual",
   "language": "python",
   "name": "cross-lingual"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

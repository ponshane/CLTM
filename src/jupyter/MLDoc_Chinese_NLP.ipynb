{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# set python syspath to point out location of our self-writing module\n",
    "sys.path.append(\"/home/ponshane/work_dir/CLTM/src/codebase/\")\n",
    "\n",
    "import configparser\n",
    "from datetime import datetime\n",
    "from pymongo import MongoClient\n",
    "from Sentence_Segmentation import Sentence_Segmentation\n",
    "from Chinese_Tokenizer import Tokenizer\n",
    "from Chinese_POSTagger import POSTagger\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### init and read config\n",
    "config = configparser.ConfigParser()\n",
    "config.read('../config.ini')\n",
    "\n",
    "### connect to mongodb\n",
    "MongoDB = config[\"MLDoc\"][\"Database\"]\n",
    "MongoUser = config[\"MLDoc\"][\"User\"]\n",
    "MongoPW = config[\"MLDoc\"][\"PW\"]\n",
    "\n",
    "uri = \"mongodb://\" + MongoUser + \":\" + MongoPW + \"@140.117.69.70:30241/\" + MongoDB + \"?authMechanism=SCRAM-SHA-1\"\n",
    "\n",
    "client = MongoClient(uri)\n",
    "db = client.MLDoc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_id': ObjectId('5bf419bdd3d28003f2b4057c'), 'Class': 'CCAT', 'Content': ' [路透社香港14日電]    中國最大的電子彩   管生產商--深圳賽格股份有限公司表示,今年上半年   因產量增加,預計97年上半年稅后利潤增幅約30%.   據深賽格96年報顯示,96年實現稅后利潤   1.42億元人民幣,96年中期實現6,017萬元.   該公司的一位人士對香港中國証券快訊表示,   盡管賽格公司實施了96年每10股送3股的分紅方案,但   97年上半年的利潤仍保持在0.29元左右.但他未說明是   根據國內會計標准抑或境外會計標准.   他指出,利潤增加的主要原因是公司產品產量   的提高和其它投資收益,包括已在深圳完工的諸運大   廈,不過他未給出具體細節.   深賽格2,120萬股A股于96年12月26日在深圳   掛牌.8,000萬B股亦于96年7月22日在深掛牌. (完)   (c) Reuters Limited 1997 ', 'Sub_corpus': 'FDCH14', 'File_name': '29566'}\n",
      "['路透社香港日电中国最大的电子彩管生产商深圳赛格股份有限公司表示,今年上半年因产量增加,预计年上半年税后利润增幅约', '据深赛格年报显示,年实现税后利润', '亿元人民币,年中期实现,万元', '该公司的一位人士对香港中国証券快讯表示,尽管赛格公司实施了年每股送股的分红方案,但年上半年的利润仍保持在', '元左右', '但他未说明是根据国内会计标准抑或境外会计标准', '他指出,利润增加的主要原因是公司产品产量的提高和其它投资收益,包括已在深圳完工的诸运大厦,不过他未给出具体细节', '深赛格,万股A股于年月日在深圳挂牌', ',万B股亦于年月日在深挂牌', '完cReutersLimited']\n",
      "[['路透社', '香港', '日电', '中国', '最大', '的', '电子', '彩管', '生产商', '深圳', '赛格', '股份', '有限公司', '表示', ',', '今年', '上半年', '因', '产量', '增加', ',', '预计', '年', '上半年', '税后', '利润', '增幅', '约'], ['据', '深赛格', '年报', '显示', ',', '年', '实现', '税后', '利润'], ['亿元', '人民币', ',', '年', '中期', '实现', ',', '万元'], ['该', '公司', '的', '一位', '人士', '对', '香港', '中国', '証', '券', '快讯', '表示', ',', '尽管', '赛格', '公司', '实施', '了', '年', '每股', '送股', '的', '分红', '方案', ',', '但', '年', '上半年', '的', '利润', '仍', '保持', '在'], ['元', '左右'], ['但', '他', '未说明', '是', '根据', '国内', '会计', '标准', '抑或', '境外', '会计', '标准'], ['他', '指出', ',', '利润', '增加', '的', '主要', '原因', '是', '公司', '产品产量', '的', '提高', '和', '其它', '投资收益', ',', '包括', '已', '在', '深圳', '完工', '的', '诸运', '大厦', ',', '不过', '他', '未', '给出', '具体', '细节'], ['深赛格', ',', '万股', 'A股', '于', '年月日', '在', '深圳', '挂牌'], [',', '万', 'B股', '亦', '于', '年月日', '在', '深', '挂牌'], ['完', 'cReutersLimited']]\n",
      "[['路透社#NR', '香港#NR', '日电#JJ', '中国#NR', '最大#JJ', '的#DEG', '电子#NN', '彩管#NN', '生产商#NN', '深圳#NR', '赛格#NR', '股份#NN', '有限公司#VV', '表示#VV', ',#PU', '今年#NT', '上半年#NT', '因#P', '产量#NN', '增加#VV', ',#PU', '预计#VV', '年#JJ', '上半年#NN', '税后#JJ', '利润#NN', '增幅#NN', '约#AD'], ['据#P', '深赛格#JJ', '年报#NN', '显示#VV', ',#PU', '年#AD', '实现#VV', '税后#JJ', '利润#NN'], ['亿元#VV', '人民币#NN', ',#PU', '年#JJ', '中期#NN', '实现#VV', ',#PU', '万元#NR'], ['该#DT', '公司#NN', '的#DEG', '一位#JJ', '人士#NN', '对#P', '香港#NR', '中国#NR', '証#VV', '券#NN', '快讯#NN', '表示#VV', ',#PU', '尽管#CS', '赛格#NR', '公司#NN', '实施#VV', '了#AS', '年#NN', '每股#NN', '送股#VV', '的#DEC', '分红#VV', '方案#NN', ',#PU', '但#AD', '年#NN', '上半年#NT', '的#DEG', '利润#NN', '仍#AD', '保持#VV', '在#P'], ['元#M', '左右#LC'], ['但#AD', '他#PN', '未说明#AD', '是#VC', '根据#P', '国内#NN', '会计#NN', '标准#NN', '抑或#VV', '境外#NN', '会计#NN', '标准#NN'], ['他#PN', '指出#VV', ',#PU', '利润#NN', '增加#VV', '的#DEC', '主要#JJ', '原因#NN', '是#VC', '公司#NN', '产品产量#VV', '的#DEC', '提高#NN', '和#CC', '其它#DT', '投资收益#VV', ',#PU', '包括#VV', '已#AD', '在#P', '深圳#NR', '完工#VV', '的#DEC', '诸运#NN', '大厦#NN', ',#PU', '不过#AD', '他#PN', '未#AD', '给出#VV', '具体#JJ', '细节#NN'], ['深赛格#NN', ',#PU', '万股#NN', 'A股#NN', '于#P', '年月日#NT', '在#P', '深圳#NR', '挂牌#VV'], [',#PU', '万#CD', 'B股#NN', '亦#AD', '于#P', '年月日#NT', '在#P', '深#NR', '挂牌#VV'], ['完#VV', 'cReutersLimited#VV']]\n"
     ]
    }
   ],
   "source": [
    "one_document = db.Chinese.find_one()\n",
    "print(one_document)\n",
    "\n",
    "chi_results = Sentence_Segmentation(one_document[\"Content\"], rep_period_regexp=\"\\.\", keep_digits=False)\n",
    "print(chi_results)\n",
    "\n",
    "chi_tokens = Tokenizer(chi_results)\n",
    "print(chi_tokens)\n",
    "\n",
    "chi_pos = POSTagger(chi_tokens)\n",
    "print(chi_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 適用於中文 NLP Process 的 Update，因為中英文產出欄位不同\n",
    "def update(target_collection, doc_id, sentences, tokens, pos):\n",
    "    Result = {\"sentences\":sentences, \"tokens\": tokens, \"pos\": pos}\n",
    "    target_collection.update_one({\"_id\": doc_id},\n",
    "                      {\n",
    "                          \"$set\":{\n",
    "                              \"chi_result\": Result,\n",
    "                              \"chi_nlp_process\": True\n",
    "                          }\n",
    "                      })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24533 documents need to be processed.\n"
     ]
    }
   ],
   "source": [
    "target_collection = db.Chinese\n",
    "num = target_collection.count({\"chi_nlp_process\": {\"$exists\": False}})\n",
    "print(\"{0} documents need to be processed.\".format(num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already process 1000 documents\n",
      "Already process 2000 documents\n",
      "Already process 3000 documents\n",
      "Already process 4000 documents\n",
      "Already process 5000 documents\n",
      "Already process 6000 documents\n",
      "Already process 7000 documents\n",
      "Already process 8000 documents\n",
      "Already process 9000 documents\n",
      "Already process 10000 documents\n",
      "Already process 11000 documents\n",
      "Already process 12000 documents\n",
      "Already process 13000 documents\n",
      "Already process 14000 documents\n",
      "Already process 15000 documents\n",
      "Already process 16000 documents\n",
      "Already process 17000 documents\n",
      "Already process 18000 documents\n",
      "Already process 19000 documents\n",
      "Already process 20000 documents\n",
      "Already process 21000 documents\n",
      "Already process 22000 documents\n",
      "Already process 23000 documents\n",
      "Already process 24000 documents\n",
      "0 documents got some problems\n",
      "[]\n",
      "Time elapsed (hh:mm:ss.ms) 0:22:21.705841\n"
     ]
    }
   ],
   "source": [
    "docs = target_collection.find({\"chi_nlp_process\":{\"$exists\": False}},{\"_id\":1, \"Content\":1}, no_cursor_timeout=True)\n",
    "\n",
    "# improve version\n",
    "start_time = datetime.now()\n",
    "\n",
    "error_list = list()\n",
    "index = 0\n",
    "\n",
    "for each_document in docs:\n",
    "    sentences = Sentence_Segmentation(each_document[\"Content\"], rep_period_regexp=\"\\.\", keep_digits=False)\n",
    "    tokens = Tokenizer(sentences)\n",
    "    pos = POSTagger(tokens)\n",
    "    \n",
    "    try:\n",
    "        update(target_collection, each_document[\"_id\"], sentences, tokens, pos)\n",
    "    except:\n",
    "        error_list.append(each_document[\"_id\"])\n",
    "    \n",
    "    index += 1\n",
    "    if(index % 1000 ==0):\n",
    "        print(\"Already process %d documents\" % index)\n",
    "\n",
    "print(\"{0} documents got some problems\".format(len(error_list)))\n",
    "print(error_list)\n",
    "\n",
    "docs.close()\n",
    "\n",
    "time_elapsed = datetime.now() - start_time\n",
    "\n",
    "print('Time elapsed (hh:mm:ss.ms) {}'.format(time_elapsed))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cross-lingual]",
   "language": "python",
   "name": "conda-env-cross-lingual-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
